{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34eb2ed0",
   "metadata": {},
   "source": [
    "## Adding more phonetic transcriptions\n",
    "\n",
    "Not all the verbs found in CHILDES-DB have a transcription in `english_merged.txt`.\n",
    "\n",
    "As a workaround, we decided to try creating transcriptions for these verbs using [NLTK's CMUdict](https://www.nltk.org/api/nltk.corpus.reader.cmudict.html). \n",
    "\n",
    "CMUdict uses ARPAbet transcription. [1](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)\n",
    "\n",
    "This Jupyter/Python notebook contains code that:\n",
    "(1) obtains ARPAbet transcriptions for the verbs not in `english_merged.txt`,\n",
    "(2) uses phonecodes to get IPA, transcriptions, and\n",
    "(3) saves the stem IPA to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f049a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/miniconda3/envs/research/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/research/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/research/lib/python3.12/site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/envs/research/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/research/lib/python3.12/site-packages (from nltk) (4.67.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a65b7",
   "metadata": {},
   "source": [
    "Get list of verbs without a transcription from `verb_tokens_transcribed_ipa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d191d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('verb_tokens_transcribed.csv')\n",
    "empty_df = df[df['stem_celex_encoding'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc9e263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>speaker_role</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>stem_celex_encoding</th>\n",
       "      <th>past_tense</th>\n",
       "      <th>past_tense_celex_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says</td>\n",
       "      <td>3.000062</td>\n",
       "      <td>Mother</td>\n",
       "      <td>2530</td>\n",
       "      <td>917970</td>\n",
       "      <td>say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fit</td>\n",
       "      <td>3.000062</td>\n",
       "      <td>Mother</td>\n",
       "      <td>2530</td>\n",
       "      <td>918404</td>\n",
       "      <td>fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>let's</td>\n",
       "      <td>3.000062</td>\n",
       "      <td>Mother</td>\n",
       "      <td>2530</td>\n",
       "      <td>918416</td>\n",
       "      <td>let</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>let's</td>\n",
       "      <td>3.000062</td>\n",
       "      <td>Mother</td>\n",
       "      <td>2530</td>\n",
       "      <td>918590</td>\n",
       "      <td>let</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>read</td>\n",
       "      <td>3.000062</td>\n",
       "      <td>Mother</td>\n",
       "      <td>2530</td>\n",
       "      <td>918647</td>\n",
       "      <td>read</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218416</th>\n",
       "      <td>do</td>\n",
       "      <td>35.986365</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>16213</td>\n",
       "      <td>10465001</td>\n",
       "      <td>do</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218417</th>\n",
       "      <td>has</td>\n",
       "      <td>35.986365</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>16213</td>\n",
       "      <td>10465026</td>\n",
       "      <td>have</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218419</th>\n",
       "      <td>do</td>\n",
       "      <td>35.986365</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>16213</td>\n",
       "      <td>10465128</td>\n",
       "      <td>do</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218420</th>\n",
       "      <td>have</td>\n",
       "      <td>35.986365</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>16213</td>\n",
       "      <td>10465171</td>\n",
       "      <td>have</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218422</th>\n",
       "      <td>have</td>\n",
       "      <td>35.986365</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>16213</td>\n",
       "      <td>10465185</td>\n",
       "      <td>have</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321353 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gloss  target_child_age  speaker_role  target_child_id  utterance_id  \\\n",
       "1         says          3.000062        Mother             2530        917970   \n",
       "9          fit          3.000062        Mother             2530        918404   \n",
       "10       let's          3.000062        Mother             2530        918416   \n",
       "14       let's          3.000062        Mother             2530        918590   \n",
       "17        read          3.000062        Mother             2530        918647   \n",
       "...        ...               ...           ...              ...           ...   \n",
       "1218416     do         35.986365  Target_Child            16213      10465001   \n",
       "1218417    has         35.986365  Target_Child            16213      10465026   \n",
       "1218419     do         35.986365  Target_Child            16213      10465128   \n",
       "1218420   have         35.986365  Target_Child            16213      10465171   \n",
       "1218422   have         35.986365  Target_Child            16213      10465185   \n",
       "\n",
       "         stem stem_celex_encoding past_tense past_tense_celex_encoding  \n",
       "1         say                 NaN        NaN                       NaN  \n",
       "9         fit                 NaN        NaN                       NaN  \n",
       "10        let                 NaN        NaN                       NaN  \n",
       "14        let                 NaN        NaN                       NaN  \n",
       "17       read                 NaN        NaN                       NaN  \n",
       "...       ...                 ...        ...                       ...  \n",
       "1218416    do                 NaN        NaN                       NaN  \n",
       "1218417  have                 NaN        NaN                       NaN  \n",
       "1218419    do                 NaN        NaN                       NaN  \n",
       "1218420  have                 NaN        NaN                       NaN  \n",
       "1218422  have                 NaN        NaN                       NaN  \n",
       "\n",
       "[321353 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9e12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_to_add = empty_df['stem'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae176114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[   'say',    'fit',    'let',   'read',     'do',    'put',   'make',\n",
       "   'have',  'learn',    'dog',\n",
       " ...\n",
       "  'armor',  'crest',  'tiger',   'molt', 'flurry',   'jive',  'scone',\n",
       "  'hoove', 'lesson',   'sire']\n",
       "Length: 552, dtype: str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bc13b",
   "metadata": {},
   "source": [
    "For some reason, there seems to be some nouns in the missing verbs. \n",
    "\n",
    "We could try to filter these out with NLTK if we had the context/whole utterance, but we leave this for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f725cf",
   "metadata": {},
   "source": [
    "## Get ARPAbet transcription using CMUdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a3815d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "prondict = cmudict.dict()\n",
    "\n",
    "TAB = '\\t'\n",
    "\n",
    "# transcribed_verbs maps a verb to its transcription string\n",
    "transcribed_verbs = defaultdict(str)\n",
    "\n",
    "for verb in verbs_to_add:\n",
    "    if verb in prondict:\n",
    "        pronunciations = prondict[verb] # List of pronunciations (also a list) returned. \n",
    "        # We use the first pronunciation in the list\n",
    "        transcription = \" \".join(pronunciations[0])\n",
    "        transcribed_verbs[verb] = transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dbfe055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 552)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many transcribed verbs we have vs what we started with\n",
    "\n",
    "len(transcribed_verbs), len(verbs_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15570763",
   "metadata": {},
   "source": [
    "Note: We only have IPA transcriptions for the stem. \n",
    "\n",
    "Currently, the CSV file `verb_tokens_transcribed_ipa.csv` has transcriptions for the stem + past tense + past type (regular or irregular). \n",
    "\n",
    "Maybe the stem-only transcriptions could be used as test data for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b9a81",
   "metadata": {},
   "source": [
    "## Convert ARPAbet to IPA using phonecodes\n",
    "\n",
    "Modified code from `celexToIPA.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a6224e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting phonecodes\n",
      "  Using cached phonecodes-2.0.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Using cached phonecodes-2.0.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: phonecodes\n",
      "Successfully installed phonecodes-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install phonecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa00e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonecodes import phonecodes\n",
    "\n",
    "ipa_transcribed = defaultdict()\n",
    "\n",
    "for verb, arpa in transcribed_verbs.items():\n",
    "    ipa_transcription = phonecodes.convert(arpa, \"arpabet\", \"ipa\")\n",
    "    # Remove spaces between words in the IPA transcription\n",
    "    ipa_transcribed[verb] = ipa_transcription.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26584f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ipa_transcribed) == len(transcribed_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d139c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('say', 'sˈeɪ'), ('fit', 'fˈɪt'), ('let', 'lˈɛt'), ('read', 'ɹˈɛd'), ('do', 'dˈu'), ('put', 'pˈʊt'), ('make', 'mˈeɪk'), ('have', 'hˈæv'), ('learn', 'lˈɝn'), ('dog', 'dˈɔɡ'), ('close', 'klˈoʊs'), ('ooh', 'ˈu'), ('excuse', 'ɨkskjˈus'), ('bless', 'blˈɛs'), ('hit', 'hˈɪt'), ('use', 'jˈus'), ('wad', 'wˈɑd'), ('baby', 'bˈeɪbi'), ('record', 'ɹəkˈɔɹd'), ('shut', 'ʃˈʌt'), ('snack', 'snˈæk'), ('be', 'bˈi'), ('ribbit', 'ɹˈɪbɨt'), ('set', 'sˈɛt'), ('shampoo', 'ʃæmpˈu'), ('incorporate', 'ɨnkˈɔɹpɚˌeɪt'), ('waffle', 'wˈɑfəl'), ('jack', 'dʒˈæk'), ('best', 'bˈɛst'), ('boink', 'bˈɔɪnk'), ('ham', 'hˈæm'), ('weird', 'wˈɪɹd'), ('chicken', 'tʃˈɪkən'), ('tear', 'tˈɛɹ'), ('bam', 'bˈæm'), ('till', 'tˈɪl'), ('spill', 'spˈɪl'), ('hurt', 'hˈɝt'), ('max', 'mˈæks'), ('yuck', 'jˈʌk'), ('live', 'lˈaɪv'), ('toy', 'tˈɔɪ'), ('meow', 'miˈaʊ'), ('pop', 'pˈɑp'), ('rid', 'ɹˈɪd'), ('quack', 'kwˈæk'), ('loaf', 'lˈoʊf'), ('task', 'tˈæsk'), ('sauce', 'sˈɔs'), ('poof', 'pˈuf'), ('woof', 'wˈuf'), ('even', 'ˈivɨn'), ('vocal', 'vˈoʊkəl'), ('page', 'pˈeɪdʒ'), ('toe', 'tˈoʊ'), ('gyp', 'dʒˈɪp'), ('mouth', 'mˈaʊθ'), ('mush', 'mˈʌʃ'), ('practice', 'pɹˈæktəs'), ('cut', 'kˈʌt'), ('snug', 'snˈʌɡ'), ('spell', 'spˈɛl'), ('zipper', 'zˈɪpɚ'), ('capital', 'kˈæpətəl'), ('collar', 'kˈɑlɚ'), ('gravitate', 'ɡɹˈævɨtˌeɪt'), ('associate', 'əsˈoʊsiət'), ('depend', 'dɨpˈɛnd'), ('spread', 'spɹˈɛd'), ('upset', 'əpsˈɛt'), ('color', 'kˈʌlɚ'), ('title', 'tˈaɪtəl'), ('wind', 'wˈaɪnd'), ('split', 'splˈɪt'), ('expose', 'ɨkspˈoʊz'), ('verbal', 'vˈɝbəl'), ('category', 'kˈætəɡˌɔɹi'), ('coordinate', 'koʊˈɔɹdənət'), ('truck', 'tɹˈʌk'), ('include', 'ɨnklˈud'), ('creature', 'kɹˈitʃɚ'), ('sea', 'sˈi'), ('puree', 'pjʊɹˈeɪ'), ('except', 'ɨksˈɛpt'), ('towel', 'tˈaʊəl'), ('stink', 'stˈɪŋk'), ('bonk', 'bˈɑŋk'), ('smell', 'smˈɛl'), ('keel', 'kˈil'), ('tweet', 'twˈit'), ('beep', 'bˈip'), ('poop', 'pˈup'), ('ding', 'dˈɪŋ'), ('chitter', 'tʃˈɪtɚ'), ('reject', 'ɹɨdʒˈɛkt'), ('ruff', 'ɹˈʌf'), ('sticker', 'stˈɪkɚ'), ('gray', 'ɡɹˈeɪ'), ('velcro', 'vˈɛlkɹoʊ'), ('party', 'pˈɑɹti'), ('beat', 'bˈit'), ('king', 'kˈɪŋ'), ('trash', 'tɹˈæʃ'), ('kneel', 'nˈil'), ('wop', 'wˈɑp'), ('format', 'fˈɔɹmˌæt'), ('diaper', 'dˈaɪpɚ'), ('wee', 'wˈi'), ('juice', 'dʒˈus'), ('supplement', 'sˈʌpləmənt'), ('burn', 'bˈɝn'), ('house', 'hˈaʊs'), ('sure', 'ʃˈʊɹ'), ('protest', 'pɹˈoʊtˌɛst'), ('nosedive', 'nˈoʊzdˌaɪv'), ('ouch', 'ˈaʊtʃ'), ('maneuver', 'mənˈuvɚ'), ('food', 'fˈud'), ('cast', 'kˈæst'), ('amount', 'əmˈaʊnt'), ('implement', 'ˈɪmpləmənt'), ('pan', 'pˈæn'), ('kind', 'kˈaɪnd'), ('microphone', 'mˈaɪkɹəfˌoʊn'), ('initiate', 'ɨnˈɪʃiˌeɪt'), ('favor', 'fˈeɪvɚ'), ('recall', 'ɹˈikˌɔl'), ('parrot', 'pˈɛɹət'), ('image', 'ˈɪmədʒ'), ('analyze', 'ˈænəlˌaɪz'), ('ball', 'bˈɔl'), ('spoil', 'spˈɔɪl'), ('deprive', 'dɨpɹˈaɪv'), ('produce', 'pɹədˈus'), ('content', 'kˈɑntɛnt'), ('flavor', 'flˈeɪvɚ'), ('base', 'bˈeɪs'), ('noise', 'nˈɔɪz'), ('conduct', 'kəndˈʌkt'), ('pong', 'pˈɔŋ'), ('clunk', 'klˈʌŋk'), ('wound', 'wˈaʊnd'), ('stripe', 'stɹˈaɪp'), ('raspberry', 'ɹˈæzbˌɛɹi'), ('present', 'pɹˈɛzənt'), ('peter', 'pˈitɚ'), ('separate', 'sˈɛpɚˌeɪt'), ('sanitize', 'sˈænɨtˌaɪz'), ('lead', 'lˈɛd'), ('grocery', 'ɡɹˈoʊsɚi'), ('collect', 'kəlˈɛkt'), ('broom', 'bɹˈum'), ('bow', 'bˈaʊ'), ('brick', 'bɹˈɪk'), ('swoosh', 'swˈuʃ'), ('row', 'ɹˈoʊ'), ('yip', 'jˈɪp'), ('crayon', 'kɹˈeɪˌɑn'), ('jut', 'dʒˈʌt'), ('whoosh', 'wˈuʃ'), ('refuse', 'ɹəfjˈuz'), ('strike', 'stɹˈaɪk'), ('pavilion', 'pəvˈɪljən'), ('derive', 'dɚˈaɪv'), ('slime', 'slˈaɪm'), ('plunk', 'plˈʌŋk'), ('abuse', 'əbjˈus'), ('bike', 'bˈaɪk'), ('shimmy', 'ʃˈɪmi'), ('blade', 'blˈeɪd'), ('boot', 'bˈut'), ('moon', 'mˈun'), ('here', 'hˈiɹ'), ('way', 'wˈeɪ'), ('horse', 'hˈɔɹs'), ('fun', 'fˈʌn'), ('safety', 'sˈeɪfti'), ('frog', 'fɹˈɑɡ'), ('sheep', 'ʃˈip'), ('gold', 'ɡˈoʊld'), ('glass', 'ɡlˈæs'), ('child', 'tʃˈaɪld'), ('there', 'ðˈɛɹ'), ('cat', 'kˈæt'), ('rooster', 'ɹˈustɚ'), ('pig', 'pˈɪɡ'), ('honey', 'hˈʌni'), ('boy', 'bˈɔɪ'), ('tractor', 'tɹˈæktɚ'), ('oatmeal', 'ˈoʊtmˌil'), ('banana', 'bənˈænə'), ('sticky', 'stˈɪki'), ('cereal', 'sˈɪɹiəl'), ('pumpkin', 'pˈʌmpkɨn'), ('tree', 'tɹˈi'), ('grass', 'ɡɹˈæs'), ('car', 'kˈɑɹ'), ('can', 'kˈæn'), ('cork', 'kˈɔɹk'), ('spring', 'spɹˈɪŋ'), ('appropriate', 'əpɹˈoʊpɹiət'), ('green', 'ɡɹˈin'), ('torment', 'tˈɔɹmˌɛnt'), ('crock', 'kɹˈɑk'), ('gun', 'ɡˈʌn'), ('aspirate', 'ˈæspɚˌeɪt'), ('cracker', 'kɹˈækɚ'), ('berry', 'bˈɛɹi'), ('rise', 'ɹˈaɪz'), ('poo', 'pˈu'), ('beware', 'bɨwˈɛɹ'), ('designate', 'dˈɛzəɡnˌeɪt'), ('true', 'tɹˈu'), ('shed', 'ʃˈɛd'), ('haw', 'hˈɔ'), ('reverse', 'ɹɨvˈɝs'), ('pod', 'pˈɑd'), ('junk', 'dʒˈʌŋk'), ('nix', 'nˈɪks'), ('pummel', 'pˈʌməl'), ('acclimate', 'ˈækləmˌeɪt'), ('goose', 'ɡˈus'), ('sterile', 'stˈɛɹəl'), ('bin', 'bˈɪn'), ('age', 'ˈeɪdʒ'), ('refer', 'ɹəfˈɝ'), ('cue', 'kjˈu'), ('spam', 'spˈæm'), ('yack', 'jˈæk'), ('babbit', 'bˈæbɨt'), ('sniffle', 'snˈɪfəl'), ('rag', 'ɹˈæɡ'), ('boogie', 'bˈuɡi'), ('plow', 'plˈaʊ'), ('accessorize', 'æksˈɛsɚˌaɪz'), ('bottom', 'bˈɑtəm'), ('costume', 'kɑstˈum'), ('resume', 'ɹɨzˈum'), ('knuckle', 'nˈʌkəl'), ('somersault', 'sˈʌmɚsˌɔlt'), ('tat', 'tˈæt'), ('video', 'vˈɪdioʊ'), ('suspect', 'səspˈɛkt'), ('skunk', 'skˈʌŋk'), ('bleep', 'blˈip'), ('chin', 'tʃˈɪn'), ('dote', 'dˈoʊt'), ('tv', 'tˈivˈi'), ('mama', 'mˈɑmə'), ('seesaw', 'sˈisˌɔ'), ('bracelet', 'bɹˈeɪslət'), ('hello', 'həlˈoʊ'), ('siren', 'sˈaɪɹən'), ('daw', 'dˈɔ'), ('mouse', 'mˈaʊs'), ('penny', 'pˈɛni'), ('potato', 'pətˈeɪtˌoʊ'), ('self', 'sˈɛlf'), ('hamburger', 'hˈæmbɚɡɚ'), ('money', 'mˈʌni'), ('frisbee', 'fɹˈɪsbi'), ('hat', 'hˈæt'), ('bunny', 'bˈʌni'), ('person', 'pˈɝsən'), ('glove', 'ɡlˈʌv'), ('hem', 'hˈɛm'), ('weep', 'wˈip'), ('tromp', 'tɹˈɑmp'), ('cozy', 'kˈoʊzi'), ('noodle', 'nˈudəl'), ('congest', 'kəndʒˈɛst'), ('daddy', 'dˈædi'), ('bird', 'bˈɝd'), ('egg', 'ˈɛɡ'), ('ma', 'mˈɑ'), ('jello', 'dʒˈɛloʊ'), ('ant', 'ˈænt'), ('mommy', 'mˈɑmi'), ('comment', 'kˈɑmɛnt'), ('beef', 'bˈif'), ('sled', 'slˈɛd'), ('hay', 'hˈeɪ'), ('burst', 'bˈɝst'), ('trampoline', 'tɹˌæmpəlˈin'), ('babysat', 'bˈeɪbisˌæt'), ('quilt', 'kwˈɪlt'), ('hock', 'hˈɑk'), ('ray', 'ɹˈeɪ'), ('gross', 'ɡɹˈoʊs'), ('cave', 'kˈeɪv'), ('scarf', 'skˈɑɹf'), ('monkey', 'mˈʌŋki'), ('cookie', 'kˈʊki'), ('monster', 'mˈɑnstɚ'), ('rely', 'ɹɨlˈaɪ'), ('sledge', 'slˈɛdʒ'), ('hoover', 'hˈuvɚ'), ('ticket', 'tˈɪkət'), ('mate', 'mˈeɪt'), ('piddle', 'pˈɪdəl'), ('submerge', 'səbmˈɝdʒ'), ('blob', 'blˈɑb'), ('spade', 'spˈeɪd'), ('tootle', 'tˈutəl'), ('cupcake', 'kˈʌpkˌeɪk'), ('sow', 'sˈaʊ'), ('roast', 'ɹˈoʊst'), ('conk', 'kˈɑŋk'), ('outfit', 'ˈaʊtfˌɪt'), ('finagle', 'fˈɪnəɡəl'), ('animal', 'ˈænəməl'), ('configure', 'kənfˈɪɡjɚ'), ('mold', 'mˈoʊld'), ('object', 'ˈɑbdʒɛkt'), ('zero', 'zˈɪɹoʊ'), ('lego', 'lˈɛɡoʊ'), ('blank', 'blˈæŋk'), ('program', 'pɹˈoʊɡɹˌæm'), ('alternate', 'ˈɔltɚnət'), ('articulate', 'ɑɹtˈɪkjəlˌeɪt'), ('bobble', 'bˈɔbəl'), ('parcel', 'pˈɑɹsəl'), ('doo', 'dˈu'), ('trump', 'tɹˈʌmp'), ('disco', 'dˈɪskoʊ'), ('splat', 'splˈæt'), ('x', 'ˈɛks'), ('desert', 'dˈɛzɚt'), ('ornament', 'ˈɔɹnəmənt'), ('scissor', 'sˈɪzɚ'), ('smarten', 'smˈɑɹtən'), ('tan', 'tˈæn'), ('barrel', 'bˈæɹəl'), ('clue', 'klˈu'), ('tut', 'tˈʌt'), ('shute', 'ʃˈut'), ('dwell', 'dwˈɛl'), ('chink', 'tʃˈɪŋk'), ('coffee', 'kˈɑfi'), ('dinner', 'dˈɪnɚ'), ('magazine', 'mˈæɡəzˌin'), ('lady', 'lˈeɪdi'), ('hair', 'hˈɛɹ'), ('thing', 'θˈɪŋ'), ('pretzel', 'pɹˈɛtzəl'), ('morning', 'mˈɔɹnɨŋ'), ('girl', 'ɡˈɝl'), ('chocolate', 'tʃˈɔklət'), ('briefcase', 'bɹˈifkˌeɪs'), ('tea', 'tˈi'), ('elevator', 'ˈɛləvˌeɪtɚ'), ('chimney', 'tʃˈɪmni'), ('candy', 'kˈændi'), ('basket', 'bˈæskət'), ('convert', 'kˈɑnvɚt'), ('fob', 'fˈɔb'), ('bathe', 'bˈeɪð'), ('construct', 'kənstɹˈʌkt'), ('compress', 'kˈɑmpɹɛs'), ('card', 'kˈɑɹd'), ('rolly', 'ɹˈoʊli'), ('cramp', 'kɹˈæmp'), ('catapult', 'kˈætəpˌʌlt'), ('graduate', 'ɡɹˈædʒəwət'), ('lasso', 'lˈæsoʊ'), ('engine', 'ˈɛndʒən'), ('night', 'nˈaɪt'), ('cigarette', 'sˌɪɡɚˈɛt'), ('pill', 'pˈɪl'), ('barrette', 'bɚˈɛt'), ('apple', 'ˈæpəl'), ('baloney', 'bəlˈoʊni'), ('soup', 'sˈup'), ('cheese', 'tʃˈiz'), ('bologna', 'bəlˈoʊni'), ('dessert', 'dɨzˈɝt'), ('squiggle', 'skwˈɪɡəl'), ('opt', 'ˈɑpt'), ('pace', 'pˈeɪs'), ('pore', 'pˈɔɹ'), ('hash', 'hˈæʃ'), ('constipated', 'kˈɑnstəpˌeɪtəd'), ('duplicate', 'dˈupləkət'), ('minute', 'mˈɪnət'), ('freckle', 'fɹˈɛkəl'), ('bell', 'bˈɛl'), ('ally', 'ˈælaɪ'), ('destruct', 'dɨstɹˈʌkt'), ('core', 'kˈɔɹ'), ('message', 'mˈɛsədʒ'), ('wimp', 'wˈɪmp'), ('sum', 'sˈʌm'), ('cure', 'kjˈʊɹ'), ('bench', 'bˈɛntʃ'), ('geyser', 'ɡˈaɪzɚ'), ('gab', 'ɡˈæb'), ('forbid', 'fɚbˈɪd'), ('battery', 'bˈætɚi'), ('guitar', 'ɡɨtˈɑɹ'), ('fruit', 'fɹˈut'), ('blue', 'blˈu'), ('mom', 'mˈɑm'), ('airmail', 'ˈɛɹmˌeɪl'), ('somewhere', 'sˈʌmwˌɛɹ'), ('one', 'wˈʌn'), ('drawing', 'dɹˈɔɨŋ'), ('christmas', 'kɹˈɪsməs'), ('buggy', 'bˈʌɡi'), ('ladder', 'lˈædɚ'), ('kit', 'kˈɪt'), ('orange', 'ˈɔɹəndʒ'), ('ocean', 'ˈoʊʃən'), ('trunk', 'tɹˈʌŋk'), ('doll', 'dˈɑl'), ('hollow', 'hˈɑloʊ'), ('goad', 'ɡˈoʊd'), ('speckle', 'spˈɛkəl'), ('wang', 'wˈæŋ'), ('slit', 'slˈɪt'), ('dole', 'dˈoʊl'), ('muscle', 'mˈʌsəl'), ('travesty', 'tɹˈævəsti'), ('net', 'nˈɛt'), ('humor', 'hjˈumɚ'), ('blueberry', 'blˈubˌɛɹi'), ('shrink', 'ʃɹˈɪŋk'), ('tattle', 'tˈætəl'), ('chitchat', 'tʃˈɪttʃˌæt'), ('tatter', 'tˈætɚ'), ('compliment', 'kˈɑmpləmɛnt'), ('carol', 'kˈæɹəl'), ('bean', 'bˈin'), ('grout', 'ɡɹˈaʊt'), ('postmark', 'pˈoʊstmˌɑɹk'), ('enroll', 'ɛnɹˈoʊl'), ('harbor', 'hˈɑɹbɚ'), ('chow', 'tʃˈaʊ'), ('beard', 'bˈɪɹd'), ('honor', 'ˈɑnɚ'), ('contour', 'kˈɑntˌʊɹ'), ('bong', 'bˈɑŋ'), ('slay', 'slˈeɪ'), ('pare', 'pˈɛɹ'), ('tissue', 'tˈɪsjˌu'), ('hunker', 'hˈʌŋkɚ'), ('team', 'tˈim'), ('contact', 'kˈɑntˌækt'), ('wreath', 'ɹˈiθ'), ('microwave', 'mˈaɪkɹəwˌeɪv'), ('detour', 'dɨtˈʊɹ'), ('candle', 'kˈændəl'), ('clad', 'klˈæd'), ('hoke', 'hˈoʊk'), ('gritter', 'ɡɹˈɪtɚ'), ('steak', 'stˈeɪk'), ('lam', 'lˈæm'), ('adventure', 'ædvˈɛntʃɚ'), ('medicine', 'mˈɛdəsən'), ('weave', 'wˈiv'), ('console', 'kˈɑnsoʊl'), ('marshmallow', 'mˈɑɹʃmˌɛloʊ'), ('frank', 'fɹˈæŋk'), ('liven', 'lˈaɪvən'), ('slipper', 'slˈɪpɚ'), ('bog', 'bˈɑɡ'), ('skateboard', 'skˈeɪtbˌɔɹd'), ('pilfer', 'pˈɪlfɚ'), ('disc', 'dˈɪsk'), ('coop', 'kˈup'), ('lot', 'lˈɑt'), ('heft', 'hˈɛft'), ('chickened', 'tʃˈɪkənd'), ('wine', 'wˈaɪn'), ('scam', 'skˈæm'), ('vaccine', 'vˌæksˈin'), ('armor', 'ˈɑɹmɚ'), ('crest', 'kɹˈɛst'), ('tiger', 'tˈaɪɡɚ'), ('molt', 'mˈoʊlt'), ('flurry', 'flˈɝi'), ('jive', 'dʒˈaɪv'), ('scone', 'skˈoʊn'), ('lesson', 'lˈɛsən'), ('sire', 'sˈaɪɚ')])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_transcribed.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079d000",
   "metadata": {},
   "source": [
    "Save to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efcf8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV = \"verb_tokens_transcribed_ipa.csv\"\n",
    "OUTPUT_CSV = \"verb_tokens_transcribed_ipa_stemonly.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Add the stem transcription to ipa_transcribed\n",
    "for word, transcription in ipa_transcribed.items():\n",
    "    df.loc[df['stem'] == word, 'stem_ipa'] = transcription\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672b95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
