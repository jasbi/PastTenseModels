---
title: "Verb Extraction"
author: "Debbie Odufuwa & Jane Kwon"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(childesr)
library(tidyverse)
```

# Loading English Tokens

## Tokens for children in English corpora
```{r}
# Note: takes a few minutes to run
english_tokens <- get_tokens(collection = c("Eng-NA", "Eng-UK"),
                            role = c("target_child","Mother", "Father"),
                            token = "*")
```

# Token Processing

## Extracting Verb Tokens

### All verb tokens between 0-36 months (small dataset)
```{r}
verb_tokens_small <- english_tokens %>%
  filter(target_child_age >= 0 & target_child_age <= 36,
         part_of_speech == "v") %>%
  select(gloss, stem, target_child_age, speaker_role, target_child_id, utterance_id) %>%
  arrange(target_child_age)
verb_tokens_small
```

### All verb tokens between 0-72 months (large dataset)
```{r}
verb_tokens_large <- english_tokens %>%
  filter(target_child_age >= 0 & target_child_age <= 72,
         part_of_speech == "v") %>%
  select(gloss, stem, target_child_age, speaker_role, target_child_id, utterance_id) %>%
  arrange(target_child_age)
verb_tokens_large
```

### Saves verb token extractions to CSV file
```{r}
write.csv(verb_tokens_small, "../data/verb_tokens_small.csv", row.names = F)
```

```{r}
write.csv(verb_tokens_large, "../data/verb_tokens_large.csv", row.names = F)
```

## Extracting Untagged Tokens

### All tokens that have no tag between 0-36 months
```{r}
untagged_tokens_small <- english_tokens %>%
  filter(target_child_age >= 0 & target_child_age <= 36,
         part_of_speech == "") %>%
  select(gloss, stem, target_child_age, speaker_role, target_child_id, utterance_id) %>%
  arrange(target_child_age)
untagged_tokens_small
```

### All tokens that have no tag between 0-72 months
```{r}
untagged_tokens_large<- english_tokens %>%
  filter(target_child_age >= 0 & target_child_age <= 72,
         part_of_speech == "") %>%
  select(gloss, stem, target_child_age, speaker_role, target_child_id, utterance_id) %>%
  arrange(target_child_age)
untagged_tokens_large
```

### Helpful Info
```{r}
print(paste("Total Tokens: ", nrow(english_tokens)))

print(paste("Verb Tokens (0-36): ", nrow(verb_tokens_small)))
print(paste("Untagged Tokens (0-36): ", nrow(untagged_tokens_small)))
print(paste("Proportion Untagged Tokens (0-36): ",
            nrow(untagged_tokens_small) / nrow(english_tokens)))

print(paste("Verb Tokens (0-72): ", nrow(verb_tokens_large)))
print(paste("Untagged Tokens (0-72): ", nrow(untagged_tokens_large)))
print(paste("Proportion Untagged Tokens (0-72): ",
            nrow(untagged_tokens_large) / nrow(english_tokens)))
```

It isn't the case that a large portion of tokens in the data frame do not have
tags. So we did not go through and classify untagged verb tokens and add them 
to our verb data frame.


# CELEX Phonetic Encoding

The code below adds columns for the CELEX transcription/phonological encoding
of the stem and past tense used in Kirov and Cotterell (2018).
<!--https://github.com/ckirov/RevisitPinkerAndPrince/blob/master/experiment_1/english_merged.txt-->

## Reads in the CELEX Data Set
```{r}
celex_path <- "../data/english_merged.txt"
celex_dict <-
  read.table(celex_path, header = FALSE, sep = "\t", quote = "", fill = T,
             col.names = c("stem", "past_tense", "stem_celex",
                           "past_tense_celex", "reg_irreg"),
             stringsAsFactors = F)

celex_dict
```

## Merges CELEX info into verb_tokens_small by matching on the "stem" column
```{r}
verb_tokens_transcribed <-
  verb_tokens_small %>%
  left_join(celex_dict %>%
              select(stem, past_tense, stem_celex, past_tense_celex),
    by = "stem") %>%
  select(gloss, target_child_age, speaker_role, target_child_id,
         utterance_id, stem, stem_celex_encoding = stem_celex,
         past_tense, past_tense_celex_encoding = past_tense_celex)

verb_tokens_transcribed
```

## Saves new data frame to CSV file
```{r}
write.csv(verb_tokens_transcribed,
          "../data/verb_tokens_transcribed.csv", row.names = FALSE)
```

Use this CSV file in celexToIPA.py (!)


# Updates / To Do

1. Not every verb token in the CHILDES data frame that we created has a 
corresponding CELEX transcription used in Kirov and Cotterell (2018)

2. celexToIPA.py transcribes tokens using a different transcription scheme
  - See examples in Table 1 of the paper and compare with corresponding IPA 
  transcriptions in verb_tokens_transcribed.csv for reference
  
  Ours:   sing sIN sang s&N sɪŋ saŋ
  Kirov:  sing sIN sang s&N sɪŋ sæŋ
  
3. Unclear whether Kirov and Cotterell (2018) & CELEX transcription uses
American or British IPA.
  - See "start", "determine" - no /ɹ/ sound transcribed. Could be a mix of the two Englishes.
  - Other examples: "know" and "go" transcribed with /əʊ/ (which is the British IPA vs /oʊ/ in American IPA)
  
4. For tokens without a CELEX encoding,
  1) Extract list of words without encoding to new csv/txt
  2) Use a package to create ARPABET encodings of the words
  3) Use phonecodes python package to convert ARPABET encodings to IPA
  
  
# All Data Frames
```{r}
verb_tokens_small
verb_tokens_large
verb_tokens_transcribed
verb_tokens_transcribed_ipa
```
